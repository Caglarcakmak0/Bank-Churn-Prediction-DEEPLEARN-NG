{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
       "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df[[#'RowNumber', 'CustomerId', 'Surname',\n",
    "     'CreditScore',   'Geography',\n",
    "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "       'IsActiveMember', 'EstimatedSalary', 'Exited'\n",
    "       ]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].replace({'Female':1,'Male':0},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited', 'Geography_France',\n",
       "       'Geography_Germany', 'Geography_Spain', 'Gender_0', 'Gender_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.get_dummies(data=df, columns=['Geography', 'Gender'])\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_unique_col_values(df):\n",
    "    for column in df:\n",
    "        if df[column].dtypes == 'object':\n",
    "            print(f'{column}: {df[column].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geography: ['France' 'Spain' 'Germany']\n"
     ]
    }
   ],
   "source": [
    "print_unique_col_values(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_0</th>\n",
       "      <th>Gender_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1              True   \n",
       "1               1        112542.58       0             False   \n",
       "2               0        113931.57       1              True   \n",
       "3               0         93826.63       0              True   \n",
       "4               1         79084.10       0             False   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  Gender_0  Gender_1  \n",
       "0              False            False     False      True  \n",
       "1              False             True     False      True  \n",
       "2              False            False     False      True  \n",
       "3              False            False     False      True  \n",
       "4              False             True     False      True  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender               int64\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f26db87850>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tenure_exited_no=df[df.Exited==0].Tenure\n",
    "tenure_exited_yes=df[df.Exited==1].Tenure\n",
    "\n",
    "plt.xlabel(\"tenure\")\n",
    "plt.ylabel(\"Number Of Customers\")\n",
    "plt.title(\"Customer exit Prediction Visualiztion\")\n",
    "\n",
    "\n",
    "plt.hist([tenure_exited_yes, tenure_exited_no], rwidth=0.95, color=['green','red'],label=['exit=Yes','Churn=No'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f26fda0950>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tenure_creditcard_no=df[df.Exited==0].HasCrCard\n",
    "tenure_creditcard_yes=df[df.Exited==1].HasCrCard\n",
    "\n",
    "plt.xlabel(\"HasCrCard\")\n",
    "plt.ylabel(\"Number Of Customers\")\n",
    "plt.title(\"Customer exit Prediction Visualiztion by credit card ownership\")\n",
    "\n",
    "\n",
    "plt.hist([tenure_creditcard_yes, tenure_creditcard_no], rwidth=0.95, color=['green','red'],label=['exit=Yes','exit=No'],bins=[-0.0,1.0])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df1.drop('Exited', axis=1)\n",
    "\n",
    "# Extract the target variable\n",
    "y = df1['Exited']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scalecolls=[\"CreditScore\",\"Age\",\"Tenure\",\"Balance\",\"NumOfProducts\",\"EstimatedSalary\"]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler= MinMaxScaler()\n",
    "df1[scalecolls]=scaler.fit_transform(df[scalecolls])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[scalecolls] = scaler.fit_transform(df1[scalecolls])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenure GÖREV SÜRESİ DEMMEK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_0</th>\n",
       "      <th>Gender_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0        0.538  0.324324     0.2  0.000000       0.000000          1   \n",
       "1        0.516  0.310811     0.1  0.334031       0.000000          0   \n",
       "2        0.304  0.324324     0.8  0.636357       0.666667          1   \n",
       "3        0.698  0.283784     0.1  0.000000       0.333333          0   \n",
       "4        1.000  0.337838     0.2  0.500246       0.000000          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1         0.506735       1              True   \n",
       "1               1         0.562709       0             False   \n",
       "2               0         0.569654       1              True   \n",
       "3               0         0.469120       0              True   \n",
       "4               1         0.395400       0             False   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  Gender_0  Gender_1  \n",
       "0              False            False     False      True  \n",
       "1              False             True     False      True  \n",
       "2              False            False     False      True  \n",
       "3              False            False     False      True  \n",
       "4              False             True     False      True  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(X_train, y_train, X_test, y_test, loss):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(13, input_dim=13, activation='relu'),\n",
    "        keras.layers.Dense(10, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=100)\n",
    "\n",
    "    print(model.evaluate(X_test, y_test))\n",
    "\n",
    "    y_preds = model.predict(X_test)\n",
    "    y_preds = np.round(y_preds)\n",
    "\n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n",
    "\n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cagla\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7466 - loss: 2627.1125\n",
      "Epoch 2/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.6566 - loss: 52.1000\n",
      "Epoch 3/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.6799 - loss: 28.4290\n",
      "Epoch 4/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.6656 - loss: 36.6955\n",
      "Epoch 5/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.6827 - loss: 37.3858\n",
      "Epoch 6/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6758 - loss: 37.9383\n",
      "Epoch 7/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.6734 - loss: 40.1713\n",
      "Epoch 8/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6730 - loss: 37.4113 \n",
      "Epoch 9/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6816 - loss: 42.9991  \n",
      "Epoch 10/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6799 - loss: 35.3698\n",
      "Epoch 11/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.6828 - loss: 33.5980\n",
      "Epoch 12/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.6770 - loss: 41.2970\n",
      "Epoch 13/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.6868 - loss: 26.9473\n",
      "Epoch 14/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.6889 - loss: 45.6551\n",
      "Epoch 15/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6904 - loss: 23.6618\n",
      "Epoch 16/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6971 - loss: 35.9954\n",
      "Epoch 17/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.6934 - loss: 46.1401\n",
      "Epoch 18/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.6862 - loss: 30.3622\n",
      "Epoch 19/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.6925 - loss: 20.6066\n",
      "Epoch 20/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.7019 - loss: 25.4135\n",
      "Epoch 21/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7026 - loss: 29.4369  \n",
      "Epoch 22/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.6837 - loss: 43.7083\n",
      "Epoch 23/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.6945 - loss: 21.9803\n",
      "Epoch 24/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6838 - loss: 33.3616\n",
      "Epoch 25/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.6804 - loss: 26.7771\n",
      "Epoch 26/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.6860 - loss: 24.2807\n",
      "Epoch 27/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.6992 - loss: 22.4578\n",
      "Epoch 28/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.6762 - loss: 22.8714\n",
      "Epoch 29/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.6797 - loss: 31.5323\n",
      "Epoch 30/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.6908 - loss: 24.5006\n",
      "Epoch 31/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7044 - loss: 26.7497\n",
      "Epoch 32/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.6856 - loss: 43.5962\n",
      "Epoch 33/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6899 - loss: 27.9160\n",
      "Epoch 34/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6911 - loss: 24.7568\n",
      "Epoch 35/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6875 - loss: 28.2607\n",
      "Epoch 36/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.6754 - loss: 33.9447\n",
      "Epoch 37/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.6856 - loss: 27.9443\n",
      "Epoch 38/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.6904 - loss: 20.0601\n",
      "Epoch 39/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.6867 - loss: 22.5909\n",
      "Epoch 40/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.6915 - loss: 36.2879\n",
      "Epoch 41/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.6777 - loss: 31.1373\n",
      "Epoch 42/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7006 - loss: 25.7700\n",
      "Epoch 43/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6886 - loss: 25.3552\n",
      "Epoch 44/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.6929 - loss: 30.7284\n",
      "Epoch 45/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.7068 - loss: 35.5829\n",
      "Epoch 46/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6913 - loss: 28.7554\n",
      "Epoch 47/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6839 - loss: 25.9740\n",
      "Epoch 48/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6883 - loss: 28.6732\n",
      "Epoch 49/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.6980 - loss: 20.1925\n",
      "Epoch 50/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.7070 - loss: 22.3259\n",
      "Epoch 51/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.6835 - loss: 19.5344\n",
      "Epoch 52/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.6836 - loss: 29.4075\n",
      "Epoch 53/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.6893 - loss: 23.5946\n",
      "Epoch 54/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.7019 - loss: 24.2950\n",
      "Epoch 55/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.6922 - loss: 19.2487\n",
      "Epoch 56/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7031 - loss: 16.4189\n",
      "Epoch 57/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.6792 - loss: 27.5222\n",
      "Epoch 58/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.6851 - loss: 17.4383\n",
      "Epoch 59/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6950 - loss: 27.1361\n",
      "Epoch 60/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6972 - loss: 18.6802\n",
      "Epoch 61/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.7024 - loss: 20.2003\n",
      "Epoch 62/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.6894 - loss: 17.9711\n",
      "Epoch 63/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6990 - loss: 25.4076\n",
      "Epoch 64/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.6845 - loss: 19.1496\n",
      "Epoch 65/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.7160 - loss: 19.6254\n",
      "Epoch 66/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.6984 - loss: 19.2050\n",
      "Epoch 67/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.7021 - loss: 21.1386\n",
      "Epoch 68/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.6967 - loss: 20.6941\n",
      "Epoch 69/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6925 - loss: 15.5233 \n",
      "Epoch 70/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.7028 - loss: 20.5969\n",
      "Epoch 71/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.6942 - loss: 20.0258\n",
      "Epoch 72/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.6958 - loss: 13.0263\n",
      "Epoch 73/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.7088 - loss: 19.5385\n",
      "Epoch 74/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.7001 - loss: 14.5408\n",
      "Epoch 75/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.6949 - loss: 24.6107\n",
      "Epoch 76/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.7005 - loss: 16.1026\n",
      "Epoch 77/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 0.7031 - loss: 12.3657\n",
      "Epoch 78/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.6914 - loss: 15.8998\n",
      "Epoch 79/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6996 - loss: 18.4513 \n",
      "Epoch 80/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.6931 - loss: 19.6989\n",
      "Epoch 81/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.6934 - loss: 12.1586\n",
      "Epoch 82/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.7103 - loss: 17.9716\n",
      "Epoch 83/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.7165 - loss: 11.5057\n",
      "Epoch 84/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.6923 - loss: 19.2638\n",
      "Epoch 85/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.7118 - loss: 14.5867\n",
      "Epoch 86/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.6956 - loss: 10.1185\n",
      "Epoch 87/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.7043 - loss: 10.3447\n",
      "Epoch 88/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.7097 - loss: 14.1946\n",
      "Epoch 89/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.6949 - loss: 12.8228\n",
      "Epoch 90/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.6952 - loss: 15.4344\n",
      "Epoch 91/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7210 - loss: 12.7513\n",
      "Epoch 92/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.6708 - loss: 19.2176\n",
      "Epoch 93/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.6978 - loss: 13.1479\n",
      "Epoch 94/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.7014 - loss: 10.7680\n",
      "Epoch 95/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.6997 - loss: 14.1022\n",
      "Epoch 96/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.6986 - loss: 11.2083\n",
      "Epoch 97/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.6957 - loss: 10.5454\n",
      "Epoch 98/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.6972 - loss: 8.4461\n",
      "Epoch 99/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.6866 - loss: 15.8593\n",
      "Epoch 100/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.7096 - loss: 10.9006\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.7805 - loss: 3.3374\n",
      "[3.4760308265686035, 0.7796666622161865]\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.87      2379\n",
      "           1       0.30      0.05      0.09       621\n",
      "\n",
      "    accuracy                           0.78      3000\n",
      "   macro avg       0.55      0.51      0.48      3000\n",
      "weighted avg       0.69      0.78      0.71      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gördüğümüz gibi, dengesiz veri seti nedeniyle Sınıf 1'in hassasiyeti(precision), (hatırlama) recall ve f1 puanı çok düşük\n",
    "\n",
    "Veri Çarpıklığını azaltalım\n",
    "Method 1: Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "count_class_0, count_class_1 = df1.Exited.value_counts()\n",
    "\n",
    "# Divide by class\n",
    "df_class_0 = df1[df1['Exited'] == 0]\n",
    "df_class_1 = df1[df1['Exited'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random under-sampling:\n",
      "Exited\n",
      "0    2037\n",
      "1    2037\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Undersample 0-class and concat the DataFrames of both class\n",
    "df_class_0_under = df_class_0.sample(count_class_1) #0 sınıfındaki örnek sayısını 1 sınıfındaki örnek sayısıyla eşitlemek için 0 sınıfından rastgele örnekler seçer (df_class_0_under). Sonra her iki sınıfı df_test_under DataFrame'inde birleştirir.\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(df_test_under.Exited.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df_test_under.drop('Exited', axis='columns')\n",
    "y = df_test_under['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "1    1630\n",
       "0    1629\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of classes in training Data\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cagla\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 0.5532 - loss: 0.6907\n",
      "Epoch 2/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.5674 - loss: 0.6755\n",
      "Epoch 3/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6198 - loss: 0.6565\n",
      "Epoch 4/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.6444 - loss: 0.6404\n",
      "Epoch 5/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.6505 - loss: 0.6265\n",
      "Epoch 6/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6744 - loss: 0.6069\n",
      "Epoch 7/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.6684 - loss: 0.6013\n",
      "Epoch 8/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 0.6966 - loss: 0.5866\n",
      "Epoch 9/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.7075 - loss: 0.5769\n",
      "Epoch 10/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.7115 - loss: 0.5729\n",
      "Epoch 11/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.7249 - loss: 0.5622\n",
      "Epoch 12/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.7268 - loss: 0.5647\n",
      "Epoch 13/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.7208 - loss: 0.5600\n",
      "Epoch 14/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.7395 - loss: 0.5417\n",
      "Epoch 15/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.7268 - loss: 0.5562\n",
      "Epoch 16/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.7208 - loss: 0.5615\n",
      "Epoch 17/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.7232 - loss: 0.5545\n",
      "Epoch 18/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7405 - loss: 0.5380\n",
      "Epoch 19/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.7439 - loss: 0.5462\n",
      "Epoch 20/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7395 - loss: 0.5396\n",
      "Epoch 21/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.7500 - loss: 0.5338\n",
      "Epoch 22/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.7471 - loss: 0.5325\n",
      "Epoch 23/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.7404 - loss: 0.5275\n",
      "Epoch 24/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.7326 - loss: 0.5369\n",
      "Epoch 25/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.7622 - loss: 0.5048\n",
      "Epoch 26/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.7500 - loss: 0.5143\n",
      "Epoch 27/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.7641 - loss: 0.4981\n",
      "Epoch 28/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.7529 - loss: 0.5085\n",
      "Epoch 29/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.7686 - loss: 0.4889\n",
      "Epoch 30/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7693 - loss: 0.4831\n",
      "Epoch 31/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.7648 - loss: 0.4874\n",
      "Epoch 32/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7576 - loss: 0.4986\n",
      "Epoch 33/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.7726 - loss: 0.4871\n",
      "Epoch 34/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.7673 - loss: 0.4739\n",
      "Epoch 35/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.7751 - loss: 0.4761\n",
      "Epoch 36/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.7634 - loss: 0.4811\n",
      "Epoch 37/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.7686 - loss: 0.4741\n",
      "Epoch 38/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7713 - loss: 0.4734  \n",
      "Epoch 39/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.7652 - loss: 0.4879\n",
      "Epoch 40/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.7858 - loss: 0.4667\n",
      "Epoch 41/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.7655 - loss: 0.4748\n",
      "Epoch 42/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.7862 - loss: 0.4528\n",
      "Epoch 43/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.7887 - loss: 0.4600\n",
      "Epoch 44/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.7623 - loss: 0.4803\n",
      "Epoch 45/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.7609 - loss: 0.4817\n",
      "Epoch 46/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.7733 - loss: 0.4658\n",
      "Epoch 47/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.7752 - loss: 0.4592\n",
      "Epoch 48/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7777 - loss: 0.4645\n",
      "Epoch 49/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.7619 - loss: 0.4763\n",
      "Epoch 50/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.7793 - loss: 0.4599\n",
      "Epoch 51/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.7761 - loss: 0.4697\n",
      "Epoch 52/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.7533 - loss: 0.4805\n",
      "Epoch 53/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.7812 - loss: 0.4596\n",
      "Epoch 54/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.7696 - loss: 0.4671\n",
      "Epoch 55/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7724 - loss: 0.4661\n",
      "Epoch 56/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7620 - loss: 0.4725\n",
      "Epoch 57/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.7868 - loss: 0.4557\n",
      "Epoch 58/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.7656 - loss: 0.4756\n",
      "Epoch 59/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.7743 - loss: 0.4545\n",
      "Epoch 60/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.7689 - loss: 0.4689\n",
      "Epoch 61/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7874 - loss: 0.4491\n",
      "Epoch 62/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.7653 - loss: 0.4660\n",
      "Epoch 63/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.7843 - loss: 0.4615\n",
      "Epoch 64/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.7675 - loss: 0.4753\n",
      "Epoch 65/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.7774 - loss: 0.4629\n",
      "Epoch 66/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.7877 - loss: 0.4474\n",
      "Epoch 67/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.7846 - loss: 0.4450\n",
      "Epoch 68/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.7700 - loss: 0.4687\n",
      "Epoch 69/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.7835 - loss: 0.4415\n",
      "Epoch 70/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.7807 - loss: 0.4528\n",
      "Epoch 71/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.7793 - loss: 0.4541\n",
      "Epoch 72/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.7737 - loss: 0.4563\n",
      "Epoch 73/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.7752 - loss: 0.4661\n",
      "Epoch 74/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7836 - loss: 0.4514\n",
      "Epoch 75/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.7850 - loss: 0.4498\n",
      "Epoch 76/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.7796 - loss: 0.4517\n",
      "Epoch 77/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.7827 - loss: 0.4528\n",
      "Epoch 78/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.7928 - loss: 0.4505\n",
      "Epoch 79/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.7745 - loss: 0.4628\n",
      "Epoch 80/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.7799 - loss: 0.4483\n",
      "Epoch 81/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.7666 - loss: 0.4699\n",
      "Epoch 82/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.7833 - loss: 0.4515\n",
      "Epoch 83/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.7724 - loss: 0.4680\n",
      "Epoch 84/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.7879 - loss: 0.4428\n",
      "Epoch 85/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.7868 - loss: 0.4510\n",
      "Epoch 86/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.7550 - loss: 0.4757\n",
      "Epoch 87/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.7826 - loss: 0.4439\n",
      "Epoch 88/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.7826 - loss: 0.4507\n",
      "Epoch 89/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.7672 - loss: 0.4753\n",
      "Epoch 90/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.7630 - loss: 0.4581\n",
      "Epoch 91/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7742 - loss: 0.4545\n",
      "Epoch 92/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.7846 - loss: 0.4483\n",
      "Epoch 93/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.7845 - loss: 0.4592\n",
      "Epoch 94/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.7952 - loss: 0.4262\n",
      "Epoch 95/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.7854 - loss: 0.4494\n",
      "Epoch 96/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.7785 - loss: 0.4490\n",
      "Epoch 97/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.7732 - loss: 0.4610\n",
      "Epoch 98/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.7803 - loss: 0.4441\n",
      "Epoch 99/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.7781 - loss: 0.4442\n",
      "Epoch 100/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.7922 - loss: 0.4541\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.7685 - loss: 0.4802\n",
      "[0.5007776021957397, 0.754601240158081]\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76       408\n",
      "           1       0.77      0.73      0.75       407\n",
      "\n",
      "    accuracy                           0.75       815\n",
      "   macro avg       0.76      0.75      0.75       815\n",
      "weighted avg       0.76      0.75      0.75       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yöntem2: Aşırı Örnekleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "Exited\n",
      "0    7963\n",
      "1    7963\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Oversample 1-class and concat the DataFrames of both classes\n",
    "df_class_1_over = df_class_1.sample(count_class_0, replace=True)\n",
    "df_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(df_test_over.Exited.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df_test_over.drop('Exited', axis='columns')\n",
    "y = df_test_over['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cagla\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797us/step - accuracy: 0.5745 - loss: 0.6743\n",
      "Epoch 2/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6540 - loss: 0.6224\n",
      "Epoch 3/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.6826 - loss: 0.5951\n",
      "Epoch 4/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.6976 - loss: 0.5836\n",
      "Epoch 5/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7018 - loss: 0.5770\n",
      "Epoch 6/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.7141 - loss: 0.5576\n",
      "Epoch 7/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.7288 - loss: 0.5420\n",
      "Epoch 8/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.7366 - loss: 0.5281\n",
      "Epoch 9/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.7420 - loss: 0.5238\n",
      "Epoch 10/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7453 - loss: 0.5115\n",
      "Epoch 11/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.7492 - loss: 0.5060\n",
      "Epoch 12/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7525 - loss: 0.4983\n",
      "Epoch 13/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.7598 - loss: 0.4891\n",
      "Epoch 14/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7604 - loss: 0.4841\n",
      "Epoch 15/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.7614 - loss: 0.4802\n",
      "Epoch 16/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.7611 - loss: 0.4814\n",
      "Epoch 17/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7624 - loss: 0.4699\n",
      "Epoch 18/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.7678 - loss: 0.4676\n",
      "Epoch 19/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.7656 - loss: 0.4788\n",
      "Epoch 20/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.7708 - loss: 0.4673\n",
      "Epoch 21/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.7644 - loss: 0.4646\n",
      "Epoch 22/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.7680 - loss: 0.4728\n",
      "Epoch 23/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.7649 - loss: 0.4720\n",
      "Epoch 24/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.7669 - loss: 0.4686\n",
      "Epoch 25/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.7636 - loss: 0.4724\n",
      "Epoch 26/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7658 - loss: 0.4668\n",
      "Epoch 27/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.7731 - loss: 0.4584\n",
      "Epoch 28/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7706 - loss: 0.4651\n",
      "Epoch 29/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.7724 - loss: 0.4609\n",
      "Epoch 30/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7729 - loss: 0.4608\n",
      "Epoch 31/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.7702 - loss: 0.4607\n",
      "Epoch 32/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.7751 - loss: 0.4554\n",
      "Epoch 33/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.7661 - loss: 0.4656\n",
      "Epoch 34/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7732 - loss: 0.4554\n",
      "Epoch 35/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.7649 - loss: 0.4673\n",
      "Epoch 36/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.7725 - loss: 0.4592\n",
      "Epoch 37/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.7704 - loss: 0.4659\n",
      "Epoch 38/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.7717 - loss: 0.4626\n",
      "Epoch 39/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.7769 - loss: 0.4518\n",
      "Epoch 40/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.7669 - loss: 0.4661\n",
      "Epoch 41/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7753 - loss: 0.4547\n",
      "Epoch 42/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7793 - loss: 0.4579\n",
      "Epoch 43/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.7757 - loss: 0.4541\n",
      "Epoch 44/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7825 - loss: 0.4571\n",
      "Epoch 45/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.7819 - loss: 0.4478\n",
      "Epoch 46/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.7750 - loss: 0.4615\n",
      "Epoch 47/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7708 - loss: 0.4610\n",
      "Epoch 48/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7789 - loss: 0.4561\n",
      "Epoch 49/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.7738 - loss: 0.4556\n",
      "Epoch 50/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.7802 - loss: 0.4533\n",
      "Epoch 51/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.7715 - loss: 0.4612\n",
      "Epoch 52/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.7826 - loss: 0.4489\n",
      "Epoch 53/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 784us/step - accuracy: 0.7753 - loss: 0.4543\n",
      "Epoch 54/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.7803 - loss: 0.4533\n",
      "Epoch 55/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.7839 - loss: 0.4434\n",
      "Epoch 56/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7829 - loss: 0.4488\n",
      "Epoch 57/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.7791 - loss: 0.4562\n",
      "Epoch 58/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.7789 - loss: 0.4453\n",
      "Epoch 59/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.7804 - loss: 0.4530\n",
      "Epoch 60/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.7805 - loss: 0.4568\n",
      "Epoch 61/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.7801 - loss: 0.4497\n",
      "Epoch 62/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.7849 - loss: 0.4518\n",
      "Epoch 63/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.7838 - loss: 0.4481\n",
      "Epoch 64/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.7889 - loss: 0.4438\n",
      "Epoch 65/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.7787 - loss: 0.4509\n",
      "Epoch 66/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.7787 - loss: 0.4551\n",
      "Epoch 67/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.7781 - loss: 0.4525\n",
      "Epoch 68/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.7785 - loss: 0.4491\n",
      "Epoch 69/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7749 - loss: 0.4596\n",
      "Epoch 70/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.7808 - loss: 0.4451\n",
      "Epoch 71/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.7832 - loss: 0.4447\n",
      "Epoch 72/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.7817 - loss: 0.4449\n",
      "Epoch 73/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7833 - loss: 0.4510\n",
      "Epoch 74/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.7827 - loss: 0.4510\n",
      "Epoch 75/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.7785 - loss: 0.4441\n",
      "Epoch 76/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.7839 - loss: 0.4452\n",
      "Epoch 77/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.7780 - loss: 0.4494\n",
      "Epoch 78/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.7823 - loss: 0.4466\n",
      "Epoch 79/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.7794 - loss: 0.4505\n",
      "Epoch 80/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.7775 - loss: 0.4487\n",
      "Epoch 81/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.7810 - loss: 0.4533\n",
      "Epoch 82/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.7752 - loss: 0.4552\n",
      "Epoch 83/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.7795 - loss: 0.4489\n",
      "Epoch 84/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7854 - loss: 0.4496\n",
      "Epoch 85/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7727 - loss: 0.4592\n",
      "Epoch 86/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7864 - loss: 0.4446  \n",
      "Epoch 87/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.7760 - loss: 0.4538\n",
      "Epoch 88/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.7796 - loss: 0.4456\n",
      "Epoch 89/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.7790 - loss: 0.4434\n",
      "Epoch 90/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.7809 - loss: 0.4441\n",
      "Epoch 91/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.7791 - loss: 0.4516\n",
      "Epoch 92/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.7821 - loss: 0.4399\n",
      "Epoch 93/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.7844 - loss: 0.4445\n",
      "Epoch 94/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.7793 - loss: 0.4405\n",
      "Epoch 95/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7778 - loss: 0.4490\n",
      "Epoch 96/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.7830 - loss: 0.4481\n",
      "Epoch 97/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.7876 - loss: 0.4401\n",
      "Epoch 98/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.7787 - loss: 0.4430\n",
      "Epoch 99/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.7765 - loss: 0.4542\n",
      "Epoch 100/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7853 - loss: 0.4426\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.7967 - loss: 0.4437\n",
      "[0.43953654170036316, 0.7947269082069397]\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1593\n",
      "           1       0.81      0.78      0.79      1593\n",
      "\n",
      "    accuracy                           0.79      3186\n",
      "   macro avg       0.80      0.79      0.79      3186\n",
      "weighted avg       0.80      0.79      0.79      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yöntem 3: SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop('Exited', axis='columns')\n",
    "y = df1['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "1    7963\n",
       "0    7963\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote= SMOTE(sampling_strategy=\"minority\")\n",
    "X_sm, y_sm =smote.fit_resample(X,y)\n",
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=15, stratify=y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cagla\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6034 - loss: 0.6618\n",
      "Epoch 2/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6784 - loss: 0.6056\n",
      "Epoch 3/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7034 - loss: 0.5723\n",
      "Epoch 4/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7110 - loss: 0.5683\n",
      "Epoch 5/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7094 - loss: 0.5671\n",
      "Epoch 6/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7182 - loss: 0.5484\n",
      "Epoch 7/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7293 - loss: 0.5420\n",
      "Epoch 8/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7375 - loss: 0.5253\n",
      "Epoch 9/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7524 - loss: 0.5109\n",
      "Epoch 10/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7554 - loss: 0.4998\n",
      "Epoch 11/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7607 - loss: 0.4853\n",
      "Epoch 12/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7713 - loss: 0.4720\n",
      "Epoch 13/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7741 - loss: 0.4719\n",
      "Epoch 14/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7748 - loss: 0.4639\n",
      "Epoch 15/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7731 - loss: 0.4640\n",
      "Epoch 16/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7687 - loss: 0.4668\n",
      "Epoch 17/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7760 - loss: 0.4613\n",
      "Epoch 18/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7789 - loss: 0.4540\n",
      "Epoch 19/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7785 - loss: 0.4628\n",
      "Epoch 20/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7830 - loss: 0.4541\n",
      "Epoch 21/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7756 - loss: 0.4584\n",
      "Epoch 22/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7785 - loss: 0.4584\n",
      "Epoch 23/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7885 - loss: 0.4407\n",
      "Epoch 24/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7897 - loss: 0.4462\n",
      "Epoch 25/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7764 - loss: 0.4633\n",
      "Epoch 26/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7774 - loss: 0.4555\n",
      "Epoch 27/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7796 - loss: 0.4531\n",
      "Epoch 28/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7891 - loss: 0.4446\n",
      "Epoch 29/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7901 - loss: 0.4408\n",
      "Epoch 30/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 0.7839 - loss: 0.4493\n",
      "Epoch 31/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.7829 - loss: 0.4531\n",
      "Epoch 32/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.7908 - loss: 0.4424\n",
      "Epoch 33/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.7850 - loss: 0.4509\n",
      "Epoch 34/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.7914 - loss: 0.4406\n",
      "Epoch 35/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.7904 - loss: 0.4373\n",
      "Epoch 36/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.7913 - loss: 0.4354\n",
      "Epoch 37/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.7947 - loss: 0.4315\n",
      "Epoch 38/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.7857 - loss: 0.4439\n",
      "Epoch 39/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7987 - loss: 0.4311\n",
      "Epoch 40/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7885 - loss: 0.4472\n",
      "Epoch 41/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7958 - loss: 0.4251  \n",
      "Epoch 42/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.7949 - loss: 0.4345\n",
      "Epoch 43/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7941 - loss: 0.4328\n",
      "Epoch 44/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.7937 - loss: 0.4314\n",
      "Epoch 45/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7998 - loss: 0.4299\n",
      "Epoch 46/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7954 - loss: 0.4283\n",
      "Epoch 47/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.7972 - loss: 0.4296\n",
      "Epoch 48/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.7979 - loss: 0.4282\n",
      "Epoch 49/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7945 - loss: 0.4309\n",
      "Epoch 50/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.7927 - loss: 0.4321\n",
      "Epoch 51/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7968 - loss: 0.4346\n",
      "Epoch 52/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.7927 - loss: 0.4313\n",
      "Epoch 53/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.7992 - loss: 0.4223\n",
      "Epoch 54/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.7958 - loss: 0.4273\n",
      "Epoch 55/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.8059 - loss: 0.4210\n",
      "Epoch 56/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7980 - loss: 0.4235\n",
      "Epoch 57/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.7998 - loss: 0.4268\n",
      "Epoch 58/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.8061 - loss: 0.4220\n",
      "Epoch 59/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.7997 - loss: 0.4260\n",
      "Epoch 60/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.7961 - loss: 0.4297\n",
      "Epoch 61/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.7951 - loss: 0.4279\n",
      "Epoch 62/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.7984 - loss: 0.4194\n",
      "Epoch 63/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8033 - loss: 0.4179\n",
      "Epoch 64/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.8068 - loss: 0.4172 \n",
      "Epoch 65/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8026 - loss: 0.4258\n",
      "Epoch 66/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.8066 - loss: 0.4148\n",
      "Epoch 67/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.8028 - loss: 0.4204\n",
      "Epoch 68/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.8028 - loss: 0.4128\n",
      "Epoch 69/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.8044 - loss: 0.4207\n",
      "Epoch 70/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.8038 - loss: 0.4164\n",
      "Epoch 71/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.8072 - loss: 0.4097\n",
      "Epoch 72/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.8035 - loss: 0.4219\n",
      "Epoch 73/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.8041 - loss: 0.4170\n",
      "Epoch 74/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8028 - loss: 0.4244\n",
      "Epoch 75/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.8084 - loss: 0.4132\n",
      "Epoch 76/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.8051 - loss: 0.4109\n",
      "Epoch 77/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.8134 - loss: 0.4063\n",
      "Epoch 78/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.8058 - loss: 0.4086\n",
      "Epoch 79/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 0.8130 - loss: 0.4045\n",
      "Epoch 80/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8057 - loss: 0.4159\n",
      "Epoch 81/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8013 - loss: 0.4231\n",
      "Epoch 82/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 0.8053 - loss: 0.4124\n",
      "Epoch 83/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.8085 - loss: 0.4049\n",
      "Epoch 84/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.8109 - loss: 0.4094\n",
      "Epoch 85/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.8087 - loss: 0.4137\n",
      "Epoch 86/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.8081 - loss: 0.4069\n",
      "Epoch 87/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8096 - loss: 0.4122\n",
      "Epoch 88/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.8093 - loss: 0.4074\n",
      "Epoch 89/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.8044 - loss: 0.4184\n",
      "Epoch 90/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.8138 - loss: 0.4016\n",
      "Epoch 91/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.8060 - loss: 0.4106\n",
      "Epoch 92/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.8073 - loss: 0.4096 \n",
      "Epoch 93/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.8103 - loss: 0.4015\n",
      "Epoch 94/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.8134 - loss: 0.4079\n",
      "Epoch 95/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.8139 - loss: 0.4038\n",
      "Epoch 96/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.8182 - loss: 0.3997\n",
      "Epoch 97/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.8191 - loss: 0.3992\n",
      "Epoch 98/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.8147 - loss: 0.4019\n",
      "Epoch 99/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.8134 - loss: 0.4031\n",
      "Epoch 100/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8140 - loss: 0.4065\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.8124 - loss: 0.4141\n",
      "[0.40033188462257385, 0.8157564401626587]\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1593\n",
      "           1       0.81      0.82      0.82      1593\n",
      "\n",
      "    accuracy                           0.82      3186\n",
      "   macro avg       0.82      0.82      0.82      3186\n",
      "weighted avg       0.82      0.82      0.82      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=15, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= X_train.copy()\n",
    "df2[\"Exited\"]= y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_0</th>\n",
       "      <th>Gender_1</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5710</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.554265</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.339721</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.371163</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980432</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>0.664</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.325318</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>0.648</td>\n",
       "      <td>0.391892</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.426077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010339</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8967</th>\n",
       "      <td>0.970</td>\n",
       "      <td>0.094595</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417230</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "5710        0.856  0.216216     0.5  0.554265       0.333333          0   \n",
       "3745        0.852  0.256757     0.1  0.371163       0.333333          1   \n",
       "5429        0.664  0.405405     0.7  0.000000       0.333333          1   \n",
       "551         0.648  0.391892     0.6  0.426077       0.000000          1   \n",
       "8967        0.970  0.094595     0.7  0.000000       0.333333          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_France  Geography_Germany  \\\n",
       "5710               0         0.339721              True              False   \n",
       "3745               1         0.980432             False               True   \n",
       "5429               0         0.325318              True              False   \n",
       "551                1         0.010339             False               True   \n",
       "8967               1         0.417230              True              False   \n",
       "\n",
       "      Geography_Spain  Gender_0  Gender_1  Exited  \n",
       "5710            False      True     False       0  \n",
       "3745            False     False      True       0  \n",
       "5429            False     False      True       0  \n",
       "551             False      True     False       1  \n",
       "8967            False      True     False       0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_class0 = df2[df2.Exited == 0]\n",
    "df2_class1 = df2[df2.Exited == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch(df_majority, df_minority, start, end):\n",
    "    df_train = pd.concat([df_majority[start:end], df_minority], axis=0)\n",
    "\n",
    "    X_train = df_train.drop('Exited', axis='columns')\n",
    "    y_train = df_train.Exited\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cagla\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 0.5294 - loss: 0.7199\n",
      "Epoch 2/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.5603 - loss: 0.6838\n",
      "Epoch 3/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.5849 - loss: 0.6784\n",
      "Epoch 4/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.6040 - loss: 0.6634\n",
      "Epoch 5/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.6439 - loss: 0.6476\n",
      "Epoch 6/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.6482 - loss: 0.6330\n",
      "Epoch 7/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.6551 - loss: 0.6187\n",
      "Epoch 8/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.6848 - loss: 0.6017\n",
      "Epoch 9/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.6839 - loss: 0.5952\n",
      "Epoch 10/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7024 - loss: 0.5873\n",
      "Epoch 11/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6998 - loss: 0.5791\n",
      "Epoch 12/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7160 - loss: 0.5700\n",
      "Epoch 13/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.7101 - loss: 0.5651\n",
      "Epoch 14/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.7309 - loss: 0.5449\n",
      "Epoch 15/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.7426 - loss: 0.5346\n",
      "Epoch 16/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.7590 - loss: 0.5156\n",
      "Epoch 17/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.7605 - loss: 0.5128\n",
      "Epoch 18/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.7619 - loss: 0.5036\n",
      "Epoch 19/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.7596 - loss: 0.5123\n",
      "Epoch 20/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.7496 - loss: 0.5169\n",
      "Epoch 21/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7541 - loss: 0.5018\n",
      "Epoch 22/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.7676 - loss: 0.4957\n",
      "Epoch 23/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.7619 - loss: 0.4933\n",
      "Epoch 24/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.7665 - loss: 0.4999\n",
      "Epoch 25/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.7548 - loss: 0.5034\n",
      "Epoch 26/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.7705 - loss: 0.4844\n",
      "Epoch 27/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.7659 - loss: 0.5003\n",
      "Epoch 28/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.7654 - loss: 0.4843\n",
      "Epoch 29/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.7708 - loss: 0.4889\n",
      "Epoch 30/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.7780 - loss: 0.4804\n",
      "Epoch 31/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.7651 - loss: 0.4827\n",
      "Epoch 32/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.7655 - loss: 0.4855\n",
      "Epoch 33/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.7849 - loss: 0.4640\n",
      "Epoch 34/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.7686 - loss: 0.4784\n",
      "Epoch 35/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.7634 - loss: 0.4801\n",
      "Epoch 36/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.7704 - loss: 0.4832\n",
      "Epoch 37/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.7694 - loss: 0.4840\n",
      "Epoch 38/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.7614 - loss: 0.4926\n",
      "Epoch 39/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.7799 - loss: 0.4806\n",
      "Epoch 40/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.7775 - loss: 0.4756\n",
      "Epoch 41/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.7719 - loss: 0.4845\n",
      "Epoch 42/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7681 - loss: 0.4846\n",
      "Epoch 43/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.7553 - loss: 0.4898\n",
      "Epoch 44/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.7604 - loss: 0.4955\n",
      "Epoch 45/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.7735 - loss: 0.4672\n",
      "Epoch 46/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.7723 - loss: 0.4786\n",
      "Epoch 47/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7759 - loss: 0.4609\n",
      "Epoch 48/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7677 - loss: 0.4924\n",
      "Epoch 49/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.7866 - loss: 0.4619\n",
      "Epoch 50/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.7732 - loss: 0.4749\n",
      "Epoch 51/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.7717 - loss: 0.4728\n",
      "Epoch 52/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.7648 - loss: 0.4801\n",
      "Epoch 53/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.7824 - loss: 0.4652\n",
      "Epoch 54/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7647 - loss: 0.4797\n",
      "Epoch 55/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.7646 - loss: 0.4873\n",
      "Epoch 56/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 0.7759 - loss: 0.4694\n",
      "Epoch 57/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7707 - loss: 0.4788\n",
      "Epoch 58/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.7742 - loss: 0.4637\n",
      "Epoch 59/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7681 - loss: 0.4766\n",
      "Epoch 60/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.7671 - loss: 0.4776\n",
      "Epoch 61/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.7682 - loss: 0.4697\n",
      "Epoch 62/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.7663 - loss: 0.4714\n",
      "Epoch 63/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.7608 - loss: 0.4912\n",
      "Epoch 64/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.7777 - loss: 0.4687\n",
      "Epoch 65/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 0.7690 - loss: 0.4774\n",
      "Epoch 66/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.7654 - loss: 0.4888\n",
      "Epoch 67/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.7766 - loss: 0.4695\n",
      "Epoch 68/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.7723 - loss: 0.4722\n",
      "Epoch 69/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.7775 - loss: 0.4773\n",
      "Epoch 70/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.7705 - loss: 0.4695\n",
      "Epoch 71/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.7611 - loss: 0.4794\n",
      "Epoch 72/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7799 - loss: 0.4596\n",
      "Epoch 73/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.7795 - loss: 0.4597\n",
      "Epoch 74/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.7628 - loss: 0.4870\n",
      "Epoch 75/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.7681 - loss: 0.4838\n",
      "Epoch 76/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.7822 - loss: 0.4541\n",
      "Epoch 77/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7779 - loss: 0.4638\n",
      "Epoch 78/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.7765 - loss: 0.4821\n",
      "Epoch 79/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7714 - loss: 0.4687\n",
      "Epoch 80/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.7763 - loss: 0.4748\n",
      "Epoch 81/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.7762 - loss: 0.4703\n",
      "Epoch 82/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.7775 - loss: 0.4657\n",
      "Epoch 83/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.7745 - loss: 0.4628\n",
      "Epoch 84/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.7587 - loss: 0.4782\n",
      "Epoch 85/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.7654 - loss: 0.4795\n",
      "Epoch 86/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - accuracy: 0.7649 - loss: 0.4760\n",
      "Epoch 87/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.7693 - loss: 0.4826\n",
      "Epoch 88/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.7724 - loss: 0.4716\n",
      "Epoch 89/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7748 - loss: 0.4759\n",
      "Epoch 90/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.7772 - loss: 0.4610\n",
      "Epoch 91/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.7698 - loss: 0.4737\n",
      "Epoch 92/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.7643 - loss: 0.4807\n",
      "Epoch 93/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.7641 - loss: 0.4772\n",
      "Epoch 94/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.7742 - loss: 0.4689\n",
      "Epoch 95/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.7703 - loss: 0.4663\n",
      "Epoch 96/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.7754 - loss: 0.4669\n",
      "Epoch 97/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.7786 - loss: 0.4652\n",
      "Epoch 98/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7815 - loss: 0.4565\n",
      "Epoch 99/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.7724 - loss: 0.4708\n",
      "Epoch 100/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7785 - loss: 0.4664\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.7457 - loss: 0.4900\n",
      "[0.4837047755718231, 0.7549999952316284]\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.75      0.83      1593\n",
      "           1       0.44      0.76      0.56       407\n",
      "\n",
      "    accuracy                           0.76      2000\n",
      "   macro avg       0.68      0.76      0.69      2000\n",
      "weighted avg       0.83      0.76      0.78      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df2_class0, df2_class1, 0, 1495)\n",
    "\n",
    "y_pred1 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cagla\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5572 - loss: 0.6843\n",
      "Epoch 2/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6271 - loss: 0.6595\n",
      "Epoch 3/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.6325 - loss: 0.6397\n",
      "Epoch 4/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.6670 - loss: 0.6172\n",
      "Epoch 5/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.6896 - loss: 0.6050\n",
      "Epoch 6/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.6882 - loss: 0.6058\n",
      "Epoch 7/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.6973 - loss: 0.5847\n",
      "Epoch 8/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7109 - loss: 0.5756  \n",
      "Epoch 9/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.7154 - loss: 0.5656\n",
      "Epoch 10/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7007 - loss: 0.5843\n",
      "Epoch 11/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.7161 - loss: 0.5667\n",
      "Epoch 12/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7301 - loss: 0.5536\n",
      "Epoch 13/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.7388 - loss: 0.5402\n",
      "Epoch 14/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7202 - loss: 0.5496\n",
      "Epoch 15/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.7154 - loss: 0.5581\n",
      "Epoch 16/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7406 - loss: 0.5388\n",
      "Epoch 17/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7250 - loss: 0.5515\n",
      "Epoch 18/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7479 - loss: 0.5212\n",
      "Epoch 19/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.7382 - loss: 0.5301\n",
      "Epoch 20/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.7441 - loss: 0.5245\n",
      "Epoch 21/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.7399 - loss: 0.5207\n",
      "Epoch 22/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.7451 - loss: 0.5159\n",
      "Epoch 23/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.7533 - loss: 0.5031\n",
      "Epoch 24/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.7532 - loss: 0.5112\n",
      "Epoch 25/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.7671 - loss: 0.4923\n",
      "Epoch 26/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.7739 - loss: 0.4832\n",
      "Epoch 27/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.7703 - loss: 0.4965\n",
      "Epoch 28/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.7868 - loss: 0.4683\n",
      "Epoch 29/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.7695 - loss: 0.4777\n",
      "Epoch 30/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.7567 - loss: 0.4958\n",
      "Epoch 31/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.7602 - loss: 0.4987\n",
      "Epoch 32/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.7649 - loss: 0.4883\n",
      "Epoch 33/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.7673 - loss: 0.4804\n",
      "Epoch 34/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.7531 - loss: 0.4913\n",
      "Epoch 35/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.7670 - loss: 0.4837\n",
      "Epoch 36/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.7601 - loss: 0.4830\n",
      "Epoch 37/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.7825 - loss: 0.4549\n",
      "Epoch 38/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.7779 - loss: 0.4710\n",
      "Epoch 39/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.7685 - loss: 0.4805\n",
      "Epoch 40/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.7739 - loss: 0.4676\n",
      "Epoch 41/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.7835 - loss: 0.4649\n",
      "Epoch 42/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.7623 - loss: 0.4835\n",
      "Epoch 43/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.7639 - loss: 0.4806\n",
      "Epoch 44/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.7579 - loss: 0.4718\n",
      "Epoch 45/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.7790 - loss: 0.4687\n",
      "Epoch 46/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.7722 - loss: 0.4779\n",
      "Epoch 47/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.7725 - loss: 0.4874\n",
      "Epoch 48/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.7755 - loss: 0.4656\n",
      "Epoch 49/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.7745 - loss: 0.4565\n",
      "Epoch 50/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.7757 - loss: 0.4635\n",
      "Epoch 51/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.7694 - loss: 0.4741\n",
      "Epoch 52/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7778 - loss: 0.4679\n",
      "Epoch 53/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.7702 - loss: 0.4673\n",
      "Epoch 54/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.7655 - loss: 0.4781\n",
      "Epoch 55/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.7712 - loss: 0.4622\n",
      "Epoch 56/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.7731 - loss: 0.4651\n",
      "Epoch 57/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.7714 - loss: 0.4672\n",
      "Epoch 58/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.7700 - loss: 0.4779\n",
      "Epoch 59/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.7697 - loss: 0.4744\n",
      "Epoch 60/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.7640 - loss: 0.4711\n",
      "Epoch 61/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.7629 - loss: 0.4734\n",
      "Epoch 62/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.7783 - loss: 0.4646\n",
      "Epoch 63/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.7833 - loss: 0.4538\n",
      "Epoch 64/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.7797 - loss: 0.4551\n",
      "Epoch 65/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.7814 - loss: 0.4500\n",
      "Epoch 66/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.7823 - loss: 0.4649\n",
      "Epoch 67/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.7830 - loss: 0.4624\n",
      "Epoch 68/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.7656 - loss: 0.4721\n",
      "Epoch 69/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.7796 - loss: 0.4501\n",
      "Epoch 70/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.7857 - loss: 0.4527\n",
      "Epoch 71/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.7753 - loss: 0.4668\n",
      "Epoch 72/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.7789 - loss: 0.4578\n",
      "Epoch 73/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.7809 - loss: 0.4536\n",
      "Epoch 74/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.7729 - loss: 0.4724\n",
      "Epoch 75/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.7800 - loss: 0.4565\n",
      "Epoch 76/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7875 - loss: 0.4511  \n",
      "Epoch 77/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.7736 - loss: 0.4642\n",
      "Epoch 78/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.7854 - loss: 0.4562\n",
      "Epoch 79/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7704 - loss: 0.4633\n",
      "Epoch 80/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.7769 - loss: 0.4671\n",
      "Epoch 81/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7687 - loss: 0.4733\n",
      "Epoch 82/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.7708 - loss: 0.4797\n",
      "Epoch 83/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.7735 - loss: 0.4656\n",
      "Epoch 84/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.7848 - loss: 0.4598\n",
      "Epoch 85/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.7813 - loss: 0.4621\n",
      "Epoch 86/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.7807 - loss: 0.4589\n",
      "Epoch 87/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.7893 - loss: 0.4480\n",
      "Epoch 88/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.7734 - loss: 0.4692\n",
      "Epoch 89/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.7946 - loss: 0.4460\n",
      "Epoch 90/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.7827 - loss: 0.4495\n",
      "Epoch 91/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.7863 - loss: 0.4524\n",
      "Epoch 92/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.7758 - loss: 0.4645\n",
      "Epoch 93/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.7922 - loss: 0.4480\n",
      "Epoch 94/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.7716 - loss: 0.4581\n",
      "Epoch 95/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.7782 - loss: 0.4549\n",
      "Epoch 96/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.7847 - loss: 0.4546\n",
      "Epoch 97/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7760 - loss: 0.4658\n",
      "Epoch 98/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.7883 - loss: 0.4404\n",
      "Epoch 99/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.7977 - loss: 0.4361\n",
      "Epoch 100/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 0.7802 - loss: 0.4572\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.7452 - loss: 0.4943\n",
      "[0.4877302646636963, 0.753000020980835]\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.74      0.83      1593\n",
      "           1       0.44      0.79      0.56       407\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.69      0.77      0.70      2000\n",
      "weighted avg       0.83      0.75      0.77      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df2_class0, df2_class1, 1495, 2990)\n",
    "\n",
    "y_pred2 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cagla\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 965us/step - accuracy: 0.5139 - loss: 0.6919\n",
      "Epoch 2/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.6467 - loss: 0.6578\n",
      "Epoch 3/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.6633 - loss: 0.6237\n",
      "Epoch 4/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.6795 - loss: 0.6042\n",
      "Epoch 5/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.6969 - loss: 0.5882\n",
      "Epoch 6/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.6711 - loss: 0.6021\n",
      "Epoch 7/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 0.6967 - loss: 0.5842\n",
      "Epoch 8/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.7076 - loss: 0.5694\n",
      "Epoch 9/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.7138 - loss: 0.5653\n",
      "Epoch 10/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.6982 - loss: 0.5839\n",
      "Epoch 11/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.7200 - loss: 0.5632\n",
      "Epoch 12/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.7094 - loss: 0.5615\n",
      "Epoch 13/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.7162 - loss: 0.5487\n",
      "Epoch 14/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.7244 - loss: 0.5398\n",
      "Epoch 15/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 0.7234 - loss: 0.5548\n",
      "Epoch 16/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.7341 - loss: 0.5491\n",
      "Epoch 17/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7293 - loss: 0.5457  \n",
      "Epoch 18/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7354 - loss: 0.5306\n",
      "Epoch 19/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.7211 - loss: 0.5474\n",
      "Epoch 20/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.7350 - loss: 0.5382\n",
      "Epoch 21/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.7433 - loss: 0.5320\n",
      "Epoch 22/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7398 - loss: 0.5336\n",
      "Epoch 23/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.7365 - loss: 0.5259\n",
      "Epoch 24/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.7321 - loss: 0.5420\n",
      "Epoch 25/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.7441 - loss: 0.5339\n",
      "Epoch 26/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.7495 - loss: 0.5161\n",
      "Epoch 27/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.7578 - loss: 0.5026\n",
      "Epoch 28/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.7606 - loss: 0.5068\n",
      "Epoch 29/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.7433 - loss: 0.5135\n",
      "Epoch 30/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 0.7688 - loss: 0.4891\n",
      "Epoch 31/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.7548 - loss: 0.5015\n",
      "Epoch 32/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.7646 - loss: 0.5008\n",
      "Epoch 33/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7676 - loss: 0.4897\n",
      "Epoch 34/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.7599 - loss: 0.5006\n",
      "Epoch 35/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.7689 - loss: 0.4874\n",
      "Epoch 36/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.7839 - loss: 0.4778\n",
      "Epoch 37/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7793 - loss: 0.4756  \n",
      "Epoch 38/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.7792 - loss: 0.4751\n",
      "Epoch 39/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.7901 - loss: 0.4759\n",
      "Epoch 40/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.7839 - loss: 0.4736\n",
      "Epoch 41/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.7834 - loss: 0.4703\n",
      "Epoch 42/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.7951 - loss: 0.4704\n",
      "Epoch 43/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.7689 - loss: 0.4789\n",
      "Epoch 44/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7854 - loss: 0.4650\n",
      "Epoch 45/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.7933 - loss: 0.4606\n",
      "Epoch 46/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.7857 - loss: 0.4612\n",
      "Epoch 47/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.7891 - loss: 0.4507\n",
      "Epoch 48/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7856 - loss: 0.4674\n",
      "Epoch 49/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.7786 - loss: 0.4722\n",
      "Epoch 50/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.7842 - loss: 0.4695\n",
      "Epoch 51/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.7725 - loss: 0.4686\n",
      "Epoch 52/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.7884 - loss: 0.4639\n",
      "Epoch 53/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7942 - loss: 0.4533  \n",
      "Epoch 54/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.7992 - loss: 0.4527\n",
      "Epoch 55/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.7840 - loss: 0.4587\n",
      "Epoch 56/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.7925 - loss: 0.4506\n",
      "Epoch 57/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7787 - loss: 0.4697\n",
      "Epoch 58/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.7857 - loss: 0.4574\n",
      "Epoch 59/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.7866 - loss: 0.4516\n",
      "Epoch 60/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.7829 - loss: 0.4658\n",
      "Epoch 61/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.7857 - loss: 0.4543\n",
      "Epoch 62/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.7971 - loss: 0.4448\n",
      "Epoch 63/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7853 - loss: 0.4559  \n",
      "Epoch 64/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.7790 - loss: 0.4583\n",
      "Epoch 65/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.7700 - loss: 0.4694\n",
      "Epoch 66/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.8018 - loss: 0.4464\n",
      "Epoch 67/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.7809 - loss: 0.4632\n",
      "Epoch 68/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.7807 - loss: 0.4548\n",
      "Epoch 69/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.7710 - loss: 0.4630\n",
      "Epoch 70/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.7859 - loss: 0.4511\n",
      "Epoch 71/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.7854 - loss: 0.4559\n",
      "Epoch 72/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.7877 - loss: 0.4522\n",
      "Epoch 73/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.7804 - loss: 0.4513\n",
      "Epoch 74/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7706 - loss: 0.4724\n",
      "Epoch 75/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.7835 - loss: 0.4564\n",
      "Epoch 76/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.7961 - loss: 0.4420\n",
      "Epoch 77/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7825 - loss: 0.4674\n",
      "Epoch 78/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.7722 - loss: 0.4698\n",
      "Epoch 79/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.7983 - loss: 0.4442\n",
      "Epoch 80/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.7869 - loss: 0.4402\n",
      "Epoch 81/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.7765 - loss: 0.4584\n",
      "Epoch 82/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.7767 - loss: 0.4575\n",
      "Epoch 83/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.7927 - loss: 0.4488\n",
      "Epoch 84/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.7738 - loss: 0.4735\n",
      "Epoch 85/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.7781 - loss: 0.4609\n",
      "Epoch 86/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.7937 - loss: 0.4308\n",
      "Epoch 87/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.7876 - loss: 0.4509\n",
      "Epoch 88/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.7935 - loss: 0.4426\n",
      "Epoch 89/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.7858 - loss: 0.4515\n",
      "Epoch 90/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7789 - loss: 0.4579\n",
      "Epoch 91/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.7864 - loss: 0.4570\n",
      "Epoch 92/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.7971 - loss: 0.4449\n",
      "Epoch 93/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.7827 - loss: 0.4399\n",
      "Epoch 94/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.7782 - loss: 0.4593\n",
      "Epoch 95/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.7881 - loss: 0.4354\n",
      "Epoch 96/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.7833 - loss: 0.4617\n",
      "Epoch 97/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.7817 - loss: 0.4519\n",
      "Epoch 98/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.7910 - loss: 0.4498\n",
      "Epoch 99/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.7850 - loss: 0.4439\n",
      "Epoch 100/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.7888 - loss: 0.4454\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.7140 - loss: 0.5518\n",
      "[0.5536144971847534, 0.7149999737739563]\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.68      0.79      1593\n",
      "           1       0.40      0.84      0.55       407\n",
      "\n",
      "    accuracy                           0.71      2000\n",
      "   macro avg       0.67      0.76      0.67      2000\n",
      "weighted avg       0.83      0.71      0.74      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, y_train = get_train_batch(df2_class0, df2_class1, 2990, 4130)\n",
    "\n",
    "y_pred3 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = y_pred1.copy()\n",
    "for i in range(len(y_pred1)):\n",
    "    n_ones = y_pred1[i] + y_pred2[i] + y_pred3[i]\n",
    "    if n_ones > 1:\n",
    "        y_pred_final[i] = 1\n",
    "    else:\n",
    "        y_pred_final[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.72      0.82      1593\n",
      "           1       0.43      0.81      0.56       407\n",
      "\n",
      "    accuracy                           0.74      2000\n",
      "   macro avg       0.68      0.77      0.69      2000\n",
      "weighted avg       0.83      0.74      0.76      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_rep = classification_report(y_test, y_pred_final)\n",
    "print(cl_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1211699732.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[47], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    f1-scoru 58 den 84 e\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "f1-scoru 58 den 82 e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "with open('Bank_Churn_Modeling.pickle','wb') as f:\n",
    "    pickle.dump(y_pred3 , f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "columns = {\n",
    "    'data_columns' : [col.lower() for col in X.columns]\n",
    "}\n",
    "with open(\"columns.json\",\"w\") as f:\n",
    "    f.write(json.dumps(columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projenin detaylı videosunu izle. Tüm yapılanları önce bir anla. Sonra gerekirse yeni bir notebookta en iyi tahmin eden ann ile ( y_pred3 bu durumda) yeni bir model olustur. sonrasında predict eden bir fonksiyon olustur. sonrasında bunu flask ile web sunucusu olusturup yaptığın siteye deploy et. Ancak sunu dene. react js ile falan siteyi biraz şaşalı hale getir. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
